Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-29 18:05:39,736 - __main__ - INFO - Server configuration:
2025-07-29 18:05:39,736 - __main__ - INFO -   Host: 0.0.0.0
2025-07-29 18:05:39,736 - __main__ - INFO -   Port: 5000
2025-07-29 18:05:39,736 - __main__ - INFO -   Debug: True
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Chat collection exists: prod1_chat
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
 * Serving Flask app 'app'
 * Debug mode: on
2025-07-29 18:05:39,738 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.103.138:5000
2025-07-29 18:05:39,738 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-07-29 18:05:39,739 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-29 18:05:50,728 - __main__ - INFO - Server configuration:
2025-07-29 18:05:50,728 - __main__ - INFO -   Host: 0.0.0.0
2025-07-29 18:05:50,728 - __main__ - INFO -   Port: 5000
2025-07-29 18:05:50,728 - __main__ - INFO -   Debug: True
2025-07-29 18:05:50,730 - werkzeug - WARNING -  * Debugger is active!
2025-07-29 18:05:50,730 - werkzeug - INFO -  * Debugger PIN: 261-137-618
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Chat collection exists: prod1_chat
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
Batches:   0%|          | 0/1 [00:00<?, ?it/s]/home/rtx4500ada/anaconda3/envs/sinon/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.33it/s]
2025-07-30 11:27:58,842 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points?wait=true "HTTP/1.1 200 OK"
ðŸ’¾ Saved message d07b7859-47b7-4624-8d60-f0e2620ac06e to Qdrant
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 177.33it/s]
2025-07-30 11:27:59,507 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/search "HTTP/1.1 200 OK"
ðŸ” Retrieved 5 initial results â†’ 5 unique sources (score â‰¥ 0.3)
>>> LLM call starting (model=meta-llama-3.2-11b-vision, client=production)
    system_prompt: 40 chars
      user_prompt: 1771 chars
        options: {'temperature': 0.4}
<<< LLM call completed in 3.0s
æ ¹æ“šå°è©±æ­·å²ï¼Œæˆ‘å€‘æ²’æœ‰ä»»ä½•ä¹‹å‰çš„å°è©±å…§å®¹ã€‚å› æ­¤ï¼Œæˆ‘å€‘ç„¡æ³•çŸ¥é“ä½ çš„å‰ä¸€å€‹å•é¡Œæ˜¯ä»€éº¼ã€‚

å¦‚æžœä½ æƒ³çŸ¥é“ä½ çš„å‰ä¸€å€‹å•é¡Œæ˜¯ä»€éº¼ï¼Œå¯ä»¥è©¦è©¦çœ‹å›žçœ‹ä¹‹å‰çš„å°è©±è¨˜éŒ„ï¼Œæˆ–æ˜¯é‡æ–°è©¢å•ä½ çš„å‰ä¸€å€‹å•é¡Œã€‚
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 160.07it/s]
2025-07-30 11:28:03,022 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points?wait=true "HTTP/1.1 200 OK"
2025-07-30 11:28:03,036 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 11:28:03] "POST /api/chat/message HTTP/1.1" 200 -
2025-07-30 11:55:29,968 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/API/routes/chat.py', reloading
ðŸ’¾ Saved message 5524678b-9837-44d6-acf8-0c336bb9a875 to Qdrant
2025-07-30 11:55:31,020 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-30 11:55:42,100 - __main__ - INFO - Server configuration:
2025-07-30 11:55:42,100 - __main__ - INFO -   Host: 0.0.0.0
2025-07-30 11:55:42,100 - __main__ - INFO -   Port: 5000
2025-07-30 11:55:42,100 - __main__ - INFO -   Debug: True
2025-07-30 11:55:42,102 - werkzeug - WARNING -  * Debugger is active!
2025-07-30 11:55:42,102 - werkzeug - INFO -  * Debugger PIN: 261-137-618
2025-07-30 11:57:42,073 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/API/routes/chat.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Chat collection exists: prod1_chat
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-07-30 11:57:43,079 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-30 11:57:53,870 - __main__ - INFO - Server configuration:
2025-07-30 11:57:53,870 - __main__ - INFO -   Host: 0.0.0.0
2025-07-30 11:57:53,870 - __main__ - INFO -   Port: 5000
2025-07-30 11:57:53,870 - __main__ - INFO -   Debug: True
2025-07-30 11:57:53,872 - werkzeug - WARNING -  * Debugger is active!
2025-07-30 11:57:53,872 - werkzeug - INFO -  * Debugger PIN: 261-137-618
2025-07-30 11:57:59,927 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/API/routes/chat.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Chat collection exists: prod1_chat
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-07-30 11:58:00,939 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-30 11:58:12,649 - __main__ - INFO - Server configuration:
2025-07-30 11:58:12,649 - __main__ - INFO -   Host: 0.0.0.0
2025-07-30 11:58:12,649 - __main__ - INFO -   Port: 5000
2025-07-30 11:58:12,649 - __main__ - INFO -   Debug: True
2025-07-30 11:58:12,651 - werkzeug - WARNING -  * Debugger is active!
2025-07-30 11:58:12,651 - werkzeug - INFO -  * Debugger PIN: 261-137-618
2025-07-30 11:58:22,745 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/test_api_payload.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Chat collection exists: prod1_chat
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-07-30 11:58:24,052 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-07-30 11:58:35,134 - __main__ - INFO - Server configuration:
2025-07-30 11:58:35,134 - __main__ - INFO -   Host: 0.0.0.0
2025-07-30 11:58:35,134 - __main__ - INFO -   Port: 5000
2025-07-30 11:58:35,134 - __main__ - INFO -   Debug: True
2025-07-30 11:58:35,136 - werkzeug - WARNING -  * Debugger is active!
2025-07-30 11:58:35,136 - werkzeug - INFO -  * Debugger PIN: 261-137-618
2025-07-30 13:40:04,428 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:40:04] "GET /health HTTP/1.1" 200 -
2025-07-30 13:40:59,992 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:40:59] "[33mDELETE /clear/5f082ff1-7c92-4328-b274-99a527687e16 HTTP/1.1[0m" 404 -
2025-07-30 13:41:15,190 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:41:15] "[33mDELETE /api/clear/5f082ff1-7c92-4328-b274-99a527687e16 HTTP/1.1[0m" 404 -
2025-07-30 13:41:46,435 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:41:46] "[33mGET /api/chat/history/ HTTP/1.1[0m" 404 -
2025-07-30 13:42:22,275 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points/delete?wait=true "HTTP/1.1 400 Bad Request"
2025-07-30 13:42:22,276 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:42:22] "[35m[1mDELETE /api/chat/clear/5f082ff1-7c92-4328-b274-99a527687e16 HTTP/1.1[0m" 500 -
2025-07-30 13:42:55,638 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points/delete?wait=true "HTTP/1.1 400 Bad Request"
2025-07-30 13:42:55,640 - werkzeug - INFO - 192.168.103.109 - - [30/Jul/2025 13:42:55] "[35m[1mDELETE /api/chat/clear/5f082ff1-7c92-4328-b274-99a527687e16 HTTP/1.1[0m" 500 -

Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:28:35,140 - __main__ - INFO - Server configuration:
2025-08-01 11:28:35,140 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:28:35,140 - __main__ - INFO -   Port: 5000
2025-08-01 11:28:35,140 - __main__ - INFO -   Debug: True
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Qdrant client connected
ðŸ“‹ Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', 'èˆˆè¾²å…¬å¸_2', 'èˆˆè¾²å…¬å¸_3', 'prod1_rooms', 'None', 'prod1', 'docs', 'èˆˆè¾²å…¬å¸', 'staging3', 'staging1']
âœ… Chat collection exists: prod1_chat
âœ… Created room_id index for chat collection
âœ… Rooms collection exists: prod1_rooms
âœ… Chat collection validated: 28 points
âœ… Rooms collection validated: 8 points
âœ… Document collection validated: 3523 points
âœ… All collections validated successfully
âœ… Document collection exists: prod1
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
 * Serving Flask app 'src.API.app'
 * Debug mode: on
2025-08-01 11:28:35,143 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.103.138:5000
2025-08-01 11:28:35,143 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-01 11:28:35,143 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:28:47,000 - __main__ - INFO - Server configuration:
2025-08-01 11:28:47,001 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:28:47,001 - __main__ - INFO -   Port: 5000
2025-08-01 11:28:47,001 - __main__ - INFO -   Debug: True
2025-08-01 11:28:47,003 - werkzeug - WARNING -  * Debugger is active!
2025-08-01 11:28:47,003 - werkzeug - INFO -  * Debugger PIN: 124-400-982
2025-08-01 11:29:08,506 - werkzeug - INFO - 192.168.103.45 - - [01/Aug/2025 11:29:08] "GET /health HTTP/1.1" 200 -
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Qdrant client connected
ðŸ“‹ Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', 'èˆˆè¾²å…¬å¸_2', 'èˆˆè¾²å…¬å¸_3', 'prod1_rooms', 'None', 'prod1', 'docs', 'èˆˆè¾²å…¬å¸', 'staging3', 'staging1']
âœ… Chat collection exists: prod1_chat
âœ… Created room_id index for chat collection
âœ… Rooms collection exists: prod1_rooms
âœ… Chat collection validated: 28 points
âœ… Rooms collection validated: 8 points
âœ… Document collection validated: 3523 points
âœ… All collections validated successfully
âœ… Document collection exists: prod1
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
ðŸ†• Creating new room for message: what is this pdf?...
ðŸ”§ Using Production LLM client: http://localhost:8000
>>> LLM call starting (model=meta-llama-3.2-11b-vision, client=production)
    system_prompt: 66 chars
      user_prompt: 500 chars
        options: {'temperature': 0.3, 'max_tokens': 20}
<<< LLM call completed in 0.4s
Batches:   0%|          | 0/1 [00:00<?, ?it/s]/home/rtx4500ada/anaconda3/envs/sinon/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  4.46it/s]
2025-08-01 11:30:01,866 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms/points?wait=true "HTTP/1.1 200 OK"
âœ… Created room 2262c88c with title: PDFå…§å®¹è©¢å•
âœ… Created room 2262c88c with title: PDFå…§å®¹è©¢å•
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 177.97it/s]
2025-08-01 11:30:02,052 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points?wait=true "HTTP/1.1 200 OK"
ðŸ’¾ Saved message 49933878-01ec-4fd7-8bfd-1d6b811618e7 to Qdrant
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 198.55it/s]
2025-08-01 11:30:02,245 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms/points?wait=true "HTTP/1.1 200 OK"
2025-08-01 11:30:02,752 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-01 11:30:03,090 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-01 11:30:03,264 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-01 11:30:03,434 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-01 11:30:03,436 - src.rag.retriever - INFO - Found 8 unique document IDs in Qdrant
Building prefix dict from the default dictionary ...
2025-08-01 11:30:03,436 - jieba - DEBUG - Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
2025-08-01 11:30:03,436 - jieba - DEBUG - Loading model from cache /tmp/jieba.cache
Loading model cost 0.457 seconds.
2025-08-01 11:30:03,892 - jieba - DEBUG - Loading model cost 0.457 seconds.
Prefix dict has been built successfully.
2025-08-01 11:30:03,893 - jieba - DEBUG - Prefix dict has been built successfully.
2025-08-01 11:30:03,896 - src.rag.retriever - INFO - Original query: what is this pdf?
2025-08-01 11:30:03,896 - src.rag.retriever - INFO - Cleaned query: what is this pdf?
2025-08-01 11:30:03,896 - src.rag.retriever - INFO - Extracted constraints: {}
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 78.32it/s]
2025-08-01 11:30:04,240 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/search "HTTP/1.1 200 OK"
2025-08-01 11:30:04,242 - src.rag.retriever - WARNING - Keyword search failed (text index missing?): QdrantClient.search() missing 1 required positional argument: 'query_vector'
2025-08-01 11:30:04,243 - src.rag.retriever - INFO - ðŸ” dense=15 keyword=0 â†’ 5 unique hits
>>> LLM call starting (model=meta-llama-3.2-11b-vision, client=production)
    system_prompt: 40 chars
      user_prompt: 1783 chars
        options: {'temperature': 0.4}
<<< LLM call completed in 9.8s
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 137.04it/s]
2025-08-01 11:30:14,759 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points?wait=true "HTTP/1.1 200 OK"
ðŸ’¾ Saved message 2a59cc35-7802-4481-b9fc-5e0008e4b2e6 to Qdrant
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00, 242.91it/s]
2025-08-01 11:30:14,948 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms/points?wait=true "HTTP/1.1 200 OK"
2025-08-01 11:30:14,950 - werkzeug - INFO - 192.168.103.45 - - [01/Aug/2025 11:30:14] "POST /api/chat/message HTTP/1.1" 200 -
2025-08-01 11:31:28,584 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/src/rag/retriever.py', reloading
2025-08-01 11:31:29,669 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:31:41,554 - __main__ - INFO - Server configuration:
2025-08-01 11:31:41,554 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:31:41,554 - __main__ - INFO -   Port: 5000
2025-08-01 11:31:41,554 - __main__ - INFO -   Debug: True
2025-08-01 11:31:41,556 - werkzeug - WARNING -  * Debugger is active!
2025-08-01 11:31:41,556 - werkzeug - INFO -  * Debugger PIN: 124-400-982
2025-08-01 11:32:04,752 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/src/rag/retriever.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Qdrant client connected
ðŸ“‹ Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', 'èˆˆè¾²å…¬å¸_2', 'èˆˆè¾²å…¬å¸_3', 'prod1_rooms', 'None', 'prod1', 'docs', 'èˆˆè¾²å…¬å¸', 'staging3', 'staging1']
âœ… Chat collection exists: prod1_chat
âœ… Created room_id index for chat collection
âœ… Rooms collection exists: prod1_rooms
âœ… Chat collection validated: 30 points
âœ… Rooms collection validated: 9 points
âœ… Document collection validated: 3523 points
âœ… All collections validated successfully
âœ… Document collection exists: prod1
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-08-01 11:32:05,764 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:32:18,067 - __main__ - INFO - Server configuration:
2025-08-01 11:32:18,067 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:32:18,067 - __main__ - INFO -   Port: 5000
2025-08-01 11:32:18,067 - __main__ - INFO -   Debug: True
2025-08-01 11:32:18,069 - werkzeug - WARNING -  * Debugger is active!
2025-08-01 11:32:18,069 - werkzeug - INFO -  * Debugger PIN: 124-400-982
2025-08-01 11:32:40,261 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/src/API/services/chat_service.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Qdrant client connected
ðŸ“‹ Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', 'èˆˆè¾²å…¬å¸_2', 'èˆˆè¾²å…¬å¸_3', 'prod1_rooms', 'None', 'prod1', 'docs', 'èˆˆè¾²å…¬å¸', 'staging3', 'staging1']
âœ… Chat collection exists: prod1_chat
âœ… Created room_id index for chat collection
âœ… Rooms collection exists: prod1_rooms
âœ… Chat collection validated: 30 points
âœ… Rooms collection validated: 9 points
âœ… Document collection validated: 3523 points
âœ… All collections validated successfully
âœ… Document collection exists: prod1
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-08-01 11:32:41,312 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:32:54,047 - __main__ - INFO - Server configuration:
2025-08-01 11:32:54,048 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:32:54,048 - __main__ - INFO -   Port: 5000
2025-08-01 11:32:54,048 - __main__ - INFO -   Debug: True
2025-08-01 11:32:54,050 - werkzeug - WARNING -  * Debugger is active!
2025-08-01 11:32:54,050 - werkzeug - INFO -  * Debugger PIN: 124-400-982
2025-08-01 11:33:22,300 - werkzeug - INFO -  * Detected change in '/home/rtx4500ada/llm-project/sinon-RAG/test_retriever_fix.py', reloading
ðŸš€ Using GPU acceleration for embeddings
ðŸ”§ Using Production LLM client: http://localhost:8000
âœ… SQLite fallback table exists
âœ… Qdrant client connected
ðŸ“‹ Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', 'èˆˆè¾²å…¬å¸_2', 'èˆˆè¾²å…¬å¸_3', 'prod1_rooms', 'None', 'prod1', 'docs', 'èˆˆè¾²å…¬å¸', 'staging3', 'staging1']
âœ… Chat collection exists: prod1_chat
âœ… Created room_id index for chat collection
âœ… Rooms collection exists: prod1_rooms
âœ… Chat collection validated: 30 points
âœ… Rooms collection validated: 9 points
âœ… Document collection validated: 3523 points
âœ… All collections validated successfully
âœ… Document collection exists: prod1
âœ… Qdrant chat service initialized
ðŸš€ Starting Sinon-RAG API Server...
âœ… Ensured directory exists: data
âœ… Ensured directory exists: data/uploads
âœ… Ensured directory exists: logs
2025-08-01 11:33:23,342 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-01 11:33:35,106 - __main__ - INFO - Server configuration:
2025-08-01 11:33:35,106 - __main__ - INFO -   Host: 0.0.0.0
2025-08-01 11:33:35,106 - __main__ - INFO -   Port: 5000
2025-08-01 11:33:35,106 - __main__ - INFO -   Debug: True
2025-08-01 11:33:35,108 - werkzeug - WARNING -  * Debugger is active!
2025-08-01 11:33:35,108 - werkzeug - INFO -  * Debugger PIN: 124-400-982

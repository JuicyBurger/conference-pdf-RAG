Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-04 16:18:29,915 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:30,426 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:31,057 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:31,607 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:32,085 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:32,289 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/index?wait=true "HTTP/1.1 200 OK"
2025-08-04 16:18:32,448 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:32,607 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat "HTTP/1.1 200 OK"
2025-08-04 16:18:32,768 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms "HTTP/1.1 200 OK"
2025-08-04 16:18:32,926 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1 "HTTP/1.1 200 OK"
2025-08-04 16:18:33,085 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:33,603 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:33,610 - __main__ - INFO - Server configuration:
2025-08-04 16:18:33,610 - __main__ - INFO -   Host: 0.0.0.0
2025-08-04 16:18:33,610 - __main__ - INFO -   Port: 5000
2025-08-04 16:18:33,610 - __main__ - INFO -   Debug: True
🚀 Using GPU acceleration for embeddings
🔧 Using Production LLM client: http://localhost:8000
✅ SQLite fallback table exists
✅ Qdrant client connected
📋 Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', '興農公司_2', 'prod1_questions', '興農公司_3', 'prod1_rooms', 'None', 'prod1', 'docs', '興農公司', 'staging3', 'staging1']
✅ Chat collection exists: prod1_chat
✅ Created room_id index for chat collection
✅ Rooms collection exists: prod1_rooms
✅ Chat collection validated: 66 points
✅ Rooms collection validated: 16 points
✅ Document collection validated: 3622 points
✅ All collections validated successfully
✅ Document collection exists: prod1
✅ Qdrant chat service initialized
🚀 Starting Sinon-RAG API Server...
✅ Ensured directory exists: data
✅ Ensured directory exists: data/uploads
✅ Ensured directory exists: logs
 * Serving Flask app 'app'
 * Debug mode: on
2025-08-04 16:18:33,612 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://192.168.103.138:5000
2025-08-04 16:18:33,612 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2025-08-04 16:18:33,613 - werkzeug - INFO -  * Restarting with stat
Some weights of BertModel were not initialized from the model checkpoint at jinaai/jina-embeddings-v2-base-zh and are newly initialized: ['embeddings.position_embeddings.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
2025-08-04 16:18:42,141 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:42,658 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:43,293 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:43,829 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:44,308 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:44,498 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/index?wait=true "HTTP/1.1 200 OK"
2025-08-04 16:18:44,657 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:44,816 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat "HTTP/1.1 200 OK"
2025-08-04 16:18:44,977 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms "HTTP/1.1 200 OK"
2025-08-04 16:18:45,136 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1 "HTTP/1.1 200 OK"
2025-08-04 16:18:45,295 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections "HTTP/1.1 200 OK"
2025-08-04 16:18:45,807 - httpx - INFO - HTTP Request: GET https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333 "HTTP/1.1 200 OK"
2025-08-04 16:18:45,814 - __main__ - INFO - Server configuration:
2025-08-04 16:18:45,814 - __main__ - INFO -   Host: 0.0.0.0
2025-08-04 16:18:45,814 - __main__ - INFO -   Port: 5000
2025-08-04 16:18:45,814 - __main__ - INFO -   Debug: True
2025-08-04 16:18:45,816 - werkzeug - WARNING -  * Debugger is active!
2025-08-04 16:18:45,817 - werkzeug - INFO -  * Debugger PIN: 435-147-969
2025-08-04 16:20:27,861 - werkzeug - INFO - 192.168.103.113 - - [04/Aug/2025 16:20:27] "OPTIONS /api/chat/message HTTP/1.1" 200 -
🚀 Using GPU acceleration for embeddings
🔧 Using Production LLM client: http://localhost:8000
✅ SQLite fallback table exists
✅ Qdrant client connected
📋 Existing collections: ['chat_messages', 'cat_rag', 'graphrag-test', 'prod1_chat', 'graphrag_collection', 'testStd', 'staging2', '興農公司_2', 'prod1_questions', '興農公司_3', 'prod1_rooms', 'None', 'prod1', 'docs', '興農公司', 'staging3', 'staging1']
✅ Chat collection exists: prod1_chat
✅ Created room_id index for chat collection
✅ Rooms collection exists: prod1_rooms
✅ Chat collection validated: 66 points
✅ Rooms collection validated: 16 points
✅ Document collection validated: 3622 points
✅ All collections validated successfully
✅ Document collection exists: prod1
✅ Qdrant chat service initialized
🚀 Starting Sinon-RAG API Server...
✅ Ensured directory exists: data
✅ Ensured directory exists: data/uploads
✅ Ensured directory exists: logs
🆕 Creating new room for content: 如何運用 AI 提升軟體開發效率？...
🔧 Using Production LLM client: http://localhost:8000
>>> LLM call starting (model=meta-llama-3.2-11b-vision, client=production)
    system_prompt: 66 chars
      user_prompt: 500 chars
        options: {'temperature': 0.3, 'max_tokens': 20}
<<< LLM call completed in 2.0s
Batches:   0%|          | 0/1 [00:00<?, ?it/s]/home/rtx4500ada/anaconda3/envs/sinon/lib/python3.12/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.
  return forward_call(*args, **kwargs)
BertSdpaSelfAttention is used but `torch.nn.functional.scaled_dot_product_attention` does not support non-absolute `position_embedding_type` or `output_attentions=True` or `head_mask`. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation="eager"` when loading the model.
Batches: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]Batches: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]
2025-08-04 16:20:30,767 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms/points?wait=true "HTTP/1.1 200 OK"
✅ Created room 6890ba1c with title: 軟體開發效率提升
✅ Created room 6890ba1c with title: 軟體開發效率提升
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 198.06it/s]
2025-08-04 16:20:30,943 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points?wait=true "HTTP/1.1 200 OK"
💾 Saved message 7dec51fc-2568-4245-b863-d50987d66156 to Qdrant
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 260.94it/s]
2025-08-04 16:20:31,129 - httpx - INFO - HTTP Request: PUT https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_rooms/points?wait=true "HTTP/1.1 200 OK"
2025-08-04 16:20:31,295 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1_chat/points/scroll "HTTP/1.1 200 OK"
2025-08-04 16:20:31,297 - routes.chat - INFO - 🔍 Chat history: 1 messages
2025-08-04 16:20:31,794 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-04 16:20:32,129 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-04 16:20:32,303 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-04 16:20:32,473 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/scroll "HTTP/1.1 200 OK"
2025-08-04 16:20:32,475 - src.rag.retriever - INFO - Found 13 unique document IDs in Qdrant
Building prefix dict from the default dictionary ...
2025-08-04 16:20:32,475 - jieba - DEBUG - Building prefix dict from the default dictionary ...
Loading model from cache /tmp/jieba.cache
2025-08-04 16:20:32,475 - jieba - DEBUG - Loading model from cache /tmp/jieba.cache
Loading model cost 0.396 seconds.
2025-08-04 16:20:32,872 - jieba - DEBUG - Loading model cost 0.396 seconds.
Prefix dict has been built successfully.
2025-08-04 16:20:32,872 - jieba - DEBUG - Prefix dict has been built successfully.
2025-08-04 16:20:32,875 - src.rag.retriever - INFO - Original query: 如何運用 AI 提升軟體開發效率？
2025-08-04 16:20:32,875 - src.rag.retriever - INFO - Cleaned query: 如何運用 AI 提升軟體開發效率？
2025-08-04 16:20:32,875 - src.rag.retriever - INFO - Extracted constraints: {}
🔍 Qdrant Chat history: 1 messages
🔍 Final Chat history: 1 messages
🔍 Searching for: '如何運用 AI 提升軟體開發效率？'
Batches:   0%|          | 0/1 [00:00<?, ?it/s]Batches: 100%|██████████| 1/1 [00:00<00:00, 97.39it/s]
2025-08-04 16:20:33,215 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/query "HTTP/1.1 200 OK"
2025-08-04 16:20:33,381 - httpx - INFO - HTTP Request: POST https://a500a585-1564-4028-b4a8-aaf693267e9f.us-west-2-0.aws.cloud.qdrant.io:6333/collections/prod1/points/query "HTTP/1.1 200 OK"
2025-08-04 16:20:33,382 - src.rag.retriever - INFO - 🔍 dense=15 keyword=0 → 5 unique hits
